{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Applied ML Projects","text":"<p>Author: Your Name Here</p> <p>This repository contains applied machine learning projects using a modern Python workflow. Each project follows a professional structure with reproducible environments, documented analysis steps, and clear results.</p> <p>Projects index:</p> <ul> <li>Project 01: Title Here</li> <li>Project 02: Title Here</li> <li>Project 03: Title Here</li> <li>Project 04: Title Here</li> </ul>"},{"location":"project01/","title":"Project 01","text":""},{"location":"project01/#overview","title":"Overview","text":"<p>Businesses and organizations often need to understand the relationships between different factors to make better decisions. For example, a company may want to predict the fuel efficiency of a car based on its weight and engine size or estimate home prices based on square footage and location. Regression analysis helps identify and quantify these relationships between numerical features, providing insights that can be used for forecasting and decision-making.</p> <p>This project demonstrates your ability to apply regression modeling techniques to a real-world dataset. You will: - Load and explore a dataset. - Choose and justify features for predicting a target variable. - Train a regression model and evaluate performance. - Compare multiple regression approaches. - Document your work in a structured Jupyter Notebook.</p>"},{"location":"project01/#dataset","title":"Dataset","text":"<p>Housing Prices Dataset (Predict home values based on features like square footage and location) - We use the built-in dataset from scikit-learn:    - <code>from sklearn.datasets import fetch_california_housing</code> - Additional dataset available on Kaggle:    - Kaggle Housing Prices </p>"},{"location":"project01/#python-library-for-machine-learning-scikit-learn","title":"Python Library for Machine Learning: scikit-learn","text":"<p>We use scikit-learn, built on NumPy, SciPy, and matplotlib    - Read more at https://scikit-learn.org/    - Scikit-learn supports classification, regression, and clustering.    - This project applies regression.</p>"},{"location":"project01/#professional-python-setup-and-workflow","title":"Professional Python Setup and Workflow","text":"<p>We follow professional Python practices.  Full instructions are available at https://github.com/denisecase/pro-analytics-02/. </p> <p>Important: VS Code + Pylance may fail to recognize installed packages in Jupyter notebooks. See the above guides for troubleshooting and solutions.  </p>"},{"location":"project01/#project-outline","title":"Project Outline","text":"<p>Machine learning projects follow a structured approach. We will use this approach throughout the course. </p> <p>Start your notebook professionally with: - a single top-level title - your name (or alias) - the date - a brief introduction that describes the problem and the dataset. - Import the external Python libraries used (e.g., pandas, numpy, matplotlib, seaborn, sklearn, etc.)</p> <p>Present your work in clearly numbered second-level and third-level headings</p>"},{"location":"project01/#section-1-load-and-explore-the-data","title":"Section 1. Load and Explore the Data","text":"<ul> <li>1.1 Load the dataset and display the first 10 rows.</li> <li>1.2 Check for missing values and display summary statistics.</li> </ul> <p>Analysis: What do you notice about the dataset? Are there any data issues?</p>"},{"location":"project01/#section-2-visualize-feature-distributions","title":"Section 2. Visualize Feature Distributions","text":"<ul> <li>2.1 Create histograms, boxplots, and scatterplots.</li> <li>2.2 Identify patterns or anomalies in feature distributions.</li> </ul> <p>Analysis: What patterns or anomalies do you see? Do any features stand out?</p>"},{"location":"project01/#section-3-feature-selection-and-justification","title":"Section 3. Feature Selection and Justification","text":"<ul> <li>3.1 Choose two input features for predicting the target.</li> <li>3.2 Justify your selection with reasoning.</li> </ul> <p>Analysis: Why did you choose these features? How might they impact predictions?</p>"},{"location":"project01/#section-4-train-a-linear-regression-model","title":"Section 4. Train a Linear Regression Model","text":"<ul> <li>4.1 Define X (features) and y (target).</li> <li>4.2 Train a Linear Regression model using Scikit-Learn.</li> <li>4.3 Report R^2, MAE, RMSE.</li> </ul> <p>Analysis: How well did the model perform? Any surprises in the results?</p> <p>See EXAMPLE_ANALYSIS for more.</p>"},{"location":"project01/#readmemd-required","title":"README.md (Required)","text":"<p>Include a professional README.md. Include: - a personalized title - an introduction to your project - a clickable link to your notebook file. - Instructions on how to set up your virtual environment and run your notebook locally.</p> <p>If starting with an assignment README, remove the parts you do not need to present your project.</p>"},{"location":"project01/EXAMPLE_ANALYSIS/","title":"Project 1 - Analysis","text":"<p>Your content here...</p>"},{"location":"project02/","title":"Project 02","text":""},{"location":"project03/","title":"Project 03","text":""},{"location":"project04/","title":"Project 04","text":""},{"location":"project06/","title":"Medical Cost Regression Project","text":"<p>Author: Deb St. Cyr</p>"},{"location":"project06/#whats-included","title":"What\u2019s Included","text":"<ul> <li> <p>A Jupyter Notebook containing all analysis steps</p> </li> <li> <p>Data exploration with visualizations</p> </li> <li> <p>A baseline Linear Regression model</p> </li> <li> <p>Improved models using Scikit-Learn pipelines</p> </li> <li> <p>A polynomial regression model that performed the best</p> </li> <li> <p>A project summary with insights and reflections</p> </li> </ul>"},{"location":"project06/#key-files","title":"Key Files","text":"<ul> <li> <p>Notebook: <code>ml_regression_stcyr.ipynb</code></p> </li> <li> <p>Summary Page: <code>PROJECT_SUMMARY.md</code> </p> </li> <li> <p>Dataset: Located in <code>data/insurance.csv</code></p> </li> </ul>"},{"location":"project06/#how-to-run-this-project","title":"How to Run This Project","text":"<pre><code>python -m venv .venv\n.venv\\Scripts\\activate       # Windows\nsource .venv/bin/activate    # Mac/Linux\n\npip install -r requirements.txt\njupyter notebook\n</code></pre> <p>Then open ml_regression_stcyr.ipynb.</p>"},{"location":"project06/PROJECT_SUMMARY/","title":"Project Summary \u2013 Regression Analysis (Medical Cost Dataset)","text":"<p>Author: Deb St. Cyr</p>"},{"location":"project06/PROJECT_SUMMARY/#dataset-overview","title":"Dataset Overview","text":"<p>The Medical Cost dataset includes basic demographic and health-related information along with each person\u2019s medical insurance charges. The features include age, sex, BMI, number of children, smoking status, and region. The target variable is charges, which is a continuous value, making regression the right choice for this project.</p> <p>There were no missing values, so most of the preparation focused on exploring the data, encoding categorical features, and understanding how each variable contributes to medical charges.</p>"},{"location":"project06/PROJECT_SUMMARY/#exploration-preprocessing","title":"Exploration &amp; Preprocessing","text":"<p>Before building any models, I created several visualizations to understand the data:</p> <ul> <li> <p>Histograms to see distributions</p> </li> <li> <p>Boxplots to spot outliers</p> </li> <li> <p>Count plots for categorical features</p> </li> <li> <p>A correlation heatmap for numerical relationships</p> </li> </ul> <p>A few things stood out:</p> <ul> <li> <p>Smokers have much higher charges compared to non-smokers.</p> </li> <li> <p>BMI has some outliers, but they appear valid.</p> </li> <li> <p>Region and sex don\u2019t seem as influential on their own.</p> </li> <li> <p>Charges are heavily skewed because a small group of individuals have very high costs.</p> </li> </ul> <p>After that, I used one-hot encoding (get_dummies) to convert the categorical variables into numeric form. No other major cleaning steps were required.</p>"},{"location":"project06/PROJECT_SUMMARY/#feature-selection","title":"Feature Selection","text":"<p>I included all available features in the model because medical costs are influenced by multiple factors. I expect age, BMI, and smoker status to be the strongest predictors, and the data exploration supported that. Region and sex may not be as strong, but they still provide additional context.</p> <p>The target variable (charges) reflects actual medical costs, which makes it ideal for regression modeling.</p>"},{"location":"project06/PROJECT_SUMMARY/#models-performance","title":"Models &amp; Performance","text":"<p>I trained three models:</p> <p>1. Baseline Linear Regression</p> <ul> <li> <p>Test R\u00b2 \u2248 0.78</p> </li> <li> <p>MAE \u2248 $4,181</p> </li> <li> <p>RMSE \u2248 $5,796</p> </li> </ul> <p>This gave me a strong baseline and showed that a simple model could already explain a good portion of the variance.</p> <p>2. Pipeline 1 \u2013 Scaled Linear Regression</p> <ul> <li> <p>Identical results to the baseline</p> </li> <li> <p>Scaling didn\u2019t change anything, which makes sense for linear regression</p> </li> </ul> <p>3. Pipeline 2 \u2013 Polynomial Regression (Degree 3)</p> <ul> <li> <p>Train R\u00b2 \u2248 0.85</p> </li> <li> <p>Test R\u00b2 \u2248 0.85</p> </li> <li> <p>Much lower MAE and RMSE</p> </li> </ul> <p>The polynomial model clearly captured more complex relationships without showing major signs of overfitting. This was the strongest model overall.</p>"},{"location":"project06/PROJECT_SUMMARY/#insights","title":"Insights","text":"<ul> <li> <p>Smoking status is by far the biggest driver of higher medical charges.</p> </li> <li> <p>BMI and age also contribute meaningfully.</p> </li> <li> <p>Linear regression alone can only capture part of the pattern.</p> </li> <li> <p>Polynomial features helped the model generalize to patterns that weren\u2019t purely linear.</p> </li> </ul> <p>If I continued this project, I would experiment with models like Random Forest, Gradient Boosting, and regularization methods such as Ridge and Lasso.</p>"},{"location":"project06/PROJECT_SUMMARY/#reflection","title":"Reflection","text":"<p>This project helped me put everything together \u2014 from exploring the data to building and comparing different models. I\u2019m still learning, but seeing how each step affects the results made things much clearer for me. The biggest surprise was how much better the polynomial model performed. It showed me that sometimes a simple linear model isn\u2019t enough to capture what\u2019s going on underneath the surface.</p>"},{"location":"project06/peer_review/","title":"Peer Review","text":"<ul> <li>Reviewer: Deb St. Cyr</li> <li>Date: November 2025</li> <li>Peer Reviewed: Branton Dawson</li> </ul>"},{"location":"project06/peer_review/#clarity-organization","title":"Clarity &amp; Organization","text":"<p>Branton\u2019s notebook is well organized and easy to follow. Each section is clearly marked, and the workflow moves logically from data loading to exploration, modeling, and evaluation. The explanations are concise and helpful, and the notebook is visually clean. One small suggestion would be to add short summaries at the start of major sections to help guide the reader on what to expect next.</p>"},{"location":"project06/peer_review/#feature-selection-justification","title":"Feature Selection &amp; Justification","text":"<p>The feature choices are appropriate for predicting medical charges. Branton provided clear justification for including variables like age, BMI, smoker status, and others, which adds credibility to the modeling decisions. As a possible enhancement, he could mention potential interactions (for example, smoker \u00d7 age or smoker \u00d7 BMI) to demonstrate awareness of more complex relationships, even if they weren\u2019t included in the final model.</p>"},{"location":"project06/peer_review/#model-performance-comparisons","title":"Model Performance &amp; Comparisons","text":"<p>Branton compared multiple models and presented the results clearly using R\u00b2, MAE, and RMSE. The comparison makes it easy to see how each model performed. A helpful addition might be a visual diagnostic plot\u2014such as predicted vs. actual charges or a residuals plot\u2014to give a deeper understanding of where the model performs well or struggles.</p>"},{"location":"project06/peer_review/#reflection-quality","title":"Reflection Quality","text":"<p>The reflections are thoughtful and show a good understanding of the results and the modeling process. Branton clearly communicated what he learned and how different modeling choices impacted performance. The reflections could be strengthened slightly by adding a brief comment on what he would explore with more time (additional models, new features, etc.).</p>"},{"location":"project06/peer_review/#overall","title":"Overall","text":"<p>Branton\u2019s project is well done\u2014clear, organized, and supported with solid explanations.  The modeling choices make sense, and the results are communicated effectively. Excellent job!</p>"}]}